{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Summary\n",
    "A balanced, dense dataset, with three classes and not many outliers.  \n",
    "Very well learned by most models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logistic Regression\n",
    "OOB Accuracy Score: 1.000000  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|1.00|1.00|1.00|18|\n",
    "|2|1.00|1.00|1.00|19|\n",
    "|3|1.00|1.00|1.00|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|1.00|1.00|1.00|54|\n",
    "|macro avg|1.00|1.00|1.00|54|\n",
    "|weighted avg|1.00|1.00|1.00|54|\n",
    "\n",
    "GridSearchCV best score: 0.975806  \n",
    "\n",
    "The accuracy of 1 is spectacular, with predictably similar statistical scores. The grid serach score of 0.98% corroborates the effectiveness of logistic regression in dealing with small, easily separable datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest\n",
    "OOB Accuracy Score: 0.962963  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|1.00|0.94|0.97|18|\n",
    "|2|0.95|0.95|0.95|19|\n",
    "|3|0.94|1.00|0.97|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|0.96|0.96|0.96|54|\n",
    "|macro avg|0.96|0.96|0.96|54|\n",
    "|weighted avg|0.96|0.96|0.96|54|\n",
    "\n",
    "GridSearchCV best score: 0.975806  \n",
    "\n",
    "Scoring lower than logistic regression with 96% accuracy, random forest appears to have been unable to perfectly separate the three classes.  Statistical scores match.  \n",
    "Grid search increased the accuracy by 1.5%, though that's still below logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### K Nearest Neighbors\n",
    "OOB Accuracy Score: 1.000000  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|1.00|1.00|1.00|18|\n",
    "|2|1.00|1.00|1.00|19|\n",
    "|3|1.00|1.00|1.00|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|1.00|1.00|1.00|54|\n",
    "|macro avg|1.00|1.00|1.00|54|\n",
    "|weighted avg|1.00|1.00|1.00|54|\n",
    "\n",
    "GridSearchCV best score: 0.959677  \n",
    "\n",
    "With perfect scores across the board, OOB k nearest neighbors shows that the classes are likely custered very separately in feature space. Grid search got only 96%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Multi-layer Perceptron - 200 iterations\n",
    "OOB Accuracy Score: 0.962963  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|1.00|0.94|0.97|18|\n",
    "|2|0.90|1.00|0.95|19|\n",
    "|3|1.00|0.94|0.97|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|0.96|0.96|0.96|54|\n",
    "|macro avg|0.97|0.96|0.96|54|\n",
    "|weighted avg|0.97|0.96|0.96|54|\n",
    "\n",
    "GridSearchCV best score: 0.991935  \n",
    "\n",
    "Start time: 12:24:42  \n",
    "End time: 12:26:46  \n",
    "\n",
    "With an unusually short training time of 2 minutes 4 seconds, MLP-200 achieved 96% accuracy with impressive F1-scores. Expectedly (in the case of a neural network) the grid search resulted in an increase of 3% in accuracy, to 99%, which is excellent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Multi-layer Perceptron - 500 iterations\n",
    "OOB Accuracy Score: 0.962963  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|1.00|0.94|0.97|18|\n",
    "|2|0.90|1.00|0.95|19|\n",
    "|3|1.00|0.94|0.97|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|0.96|0.96|0.96|54|\n",
    "|macro avg|0.97|0.96|0.96|54|\n",
    "|weighted avg|0.97|0.96|0.96|54|\n",
    "\n",
    "GridSearchCV best score: 0.983871  \n",
    "\n",
    "Start time: 12:26:46  \n",
    "End time: 12:30:18  \n",
    " \n",
    "MLP-500 achieves the same OOB accuracy as MLP-200 OOB, but worse via grid search, though statistical and f1-scores are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Support Vector Machine\n",
    "OOB Accuracy Score: 0.981481  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|1.00|0.94|0.97|18|\n",
    "|2|0.95|1.00|0.97|19|\n",
    "|3|1.00|1.00|1.00|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|0.98|0.98|0.98|54|\n",
    "|macro avg|0.98|0.98|0.98|54|\n",
    "|weighted avg|0.98|0.98|0.98|54|\n",
    "\n",
    "GridSearchCV best score: 0.983871  \n",
    "\n",
    "SVMs gained a 0.24% increase in accuracy from OOB to grid search, both being 98% accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decision Tree\n",
    "OOB Accuracy Score: 0.925926  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|0.94|0.89|0.91|18|\n",
    "|2|0.89|0.89|0.89|19|\n",
    "|3|0.94|1.00|0.97|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|0.93|0.93|0.93|54|\n",
    "|macro avg|0.93|0.93|0.93|54|\n",
    "|weighted avg|0.93|0.93|0.93|54|\n",
    "\n",
    "GridSearchCV best score: 0.911290  \n",
    "\n",
    "The decision tree achieved the worst results of all of the models used on this dataset. 93% OOB and 91% via grid search. It is likely that the decision tree would achieve much better results given a different set of parameters for it's depth, leaf numbers, and splitting decisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Naive Bayes\n",
    "OOB Accuracy Score: 0.981481  \n",
    "OOB Classification Report:  \n",
    "\n",
    "|Class|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|1|1.00|0.94|0.97|18|\n",
    "|2|0.95|1.00|0.97|19|\n",
    "|3|1.00|1.00|1.00|17|\n",
    "\n",
    "|Average|Precision|Recall|F1-score|Support|\n",
    "|---|---|---|---|---|\n",
    "|micro avg|0.98|0.98|0.98|54|\n",
    "|macro avg|0.98|0.98|0.98|54|\n",
    "|weighted avg|0.98|0.98|0.98|54|\n",
    "\n",
    "Naive Bayes got 98% OOB, which is in line with the other models trained here. The averaged statistical descriptors and f1-score are the same. It is likely a more sophisticated usage of this model would get better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Despite this dataset being very small, and with a very low ratio of data:features, only one model failed to get very good performance with it, and that model (decision tree) would likely perform similarly to the others if it had sufficient parameter tuning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
