{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "Target class numbers: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Imports and data loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import datetime\n",
    "\n",
    "# Supress the unnumbered hordes of warnings that make output completely unreadable\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'species']\n",
    "\n",
    "iris_data = pd.read_csv('../input/iris.data', names=feature_names)\n",
    "data = iris_data.loc[:, 'sepal length':'petal width']\n",
    "target = iris_data.loc[:, 'species']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(target)\n",
    "print('Target classes: {}'.format(label_encoder.classes_))\n",
    "print('Target class numbers: {}'.format(label_encoder.transform(label_encoder.classes_)))\n",
    "target_numeric = label_encoder.transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA takeaways: \n",
    "- Feature data is numeric, continuous ratio data, roughly arranged according to the normal distribution. \n",
    "- Two of the classes are not linearly separable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (105, 4)\n",
      "x_test.shape: (45, 4)\n",
      "y_train.shape: (105,)\n",
      "y_test.shape: (45,)\n",
      "standardised_x_train.shape: (105, 4)\n",
      "standardised_x_test.shape: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target_numeric, train_size=0.7, test_size=0.3, random_state=4)\n",
    "\n",
    "# Directly confirm their sizes \n",
    "print(\"x_train.shape: %s\" % str(x_train.shape))\n",
    "print(\"x_test.shape: %s\" % str(x_test.shape))\n",
    "print(\"y_train.shape: %s\" % str(y_train.shape))\n",
    "print(\"y_test.shape: %s\" % str(y_test.shape))\n",
    "\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "standardised_x_train = scaler.transform(x_train)\n",
    "standardised_x_test = scaler.transform(x_test)\n",
    "\n",
    "# Directly confirm their sizes\n",
    "print(\"standardised_x_train.shape: %s\" % str(standardised_x_train.shape))\n",
    "print(\"standardised_x_test.shape: %s\" % str(standardised_x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.933333\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        45\n",
      "   macro avg       0.92      0.93      0.92        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "GridSearchCV best score: 0.942857\n",
      "GridSearchCV best estimator: LogisticRegression(C=30, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=4, solver='warn',\n",
      "          tol=3e-06, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# OOB Logistic Regression\n",
    "lr = LogisticRegression(random_state=4)\n",
    "lr.fit(standardised_x_train, y_train)\n",
    "lr_pred = lr.predict(standardised_x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, lr_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, lr_pred))\n",
    "\n",
    "# Logistic Regression with Grid Search\n",
    "lr_gs_params = {'tol': [0.000003, 0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003], \n",
    "                'C': [0.03,0.1,0.3,1,3,10,30]}\n",
    "lr_grid = GridSearchCV(estimator=LogisticRegression(random_state=4), param_grid=lr_gs_params)\n",
    "lr_grid.fit(standardised_x_train, y_train)\n",
    "print('GridSearchCV best score: %f' % lr_grid.best_score_)\n",
    "print('GridSearchCV best estimator: %s' % lr_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.955556\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "GridSearchCV best score: 0.952381\n",
      "GridSearchCV best estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
      "            oob_score=False, random_state=4, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# OOB Random Forest\n",
    "rf = RandomForestClassifier(random_state=4)\n",
    "rf.fit(x_train, y_train)\n",
    "rf_pred = rf.predict(x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, rf_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Random Forest with Grid Search\n",
    "rf_gs_params = {'n_estimators': np.arange(5,16),\n",
    "                'min_samples_split': [2, 10, 20, 40, 80, 120]}\n",
    "rf_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=4), param_grid=rf_gs_params)\n",
    "rf_grid.fit(x_train, y_train)\n",
    "print('GridSearchCV best score: %f' % rf_grid.best_score_)\n",
    "print('GridSearchCV best estimator: %s' % rf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.955556\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "GridSearchCV best score: 0.971429\n",
      "GridSearchCV best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# OOB K Nearest Neighbors \n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(standardised_x_train, y_train)\n",
    "knn_pred = knn.predict(standardised_x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, knn_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, knn_pred))\n",
    "\n",
    "# K Nearest Neighbors with Grid Search\n",
    "knn_gs_params = {'n_neighbors': np.arange(1,16), \n",
    "                'weights': ['uniform', 'distance']}\n",
    "knn_grid = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_gs_params)\n",
    "knn_grid.fit(standardised_x_train, y_train)\n",
    "print('GridSearchCV best score: %f' % knn_grid.best_score_)\n",
    "print('GridSearchCV best estimator: %s' % knn_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-04 12:37:00.753662\n",
      "OOB Accuracy Score: 0.933333\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        45\n",
      "   macro avg       0.92      0.93      0.92        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "GridSearchCV best score: 0.971429\n",
      "GridSearchCV best estimator: MLPClassifier(activation='logistic', alpha=3e-06, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=4, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "2018-10-04 12:39:12.677550\n"
     ]
    }
   ],
   "source": [
    "# OOB Multi-layer Perceptron\n",
    "print(datetime.datetime.now())\n",
    "mlp = MLPClassifier(random_state=4)\n",
    "mlp.fit(standardised_x_train, y_train)\n",
    "mlp_pred = mlp.predict(standardised_x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, mlp_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, mlp_pred))\n",
    "\n",
    "# Multi-layer Perceptron with Grid Search\n",
    "mlp_gs_params = {'hidden_layer_sizes': [(100,), (100,100), (130,80,40)],\n",
    "                 'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                 'solver': ['lbfgs', 'sgd', 'adam'], \n",
    "                 'alpha': [0.000003, 0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003]}\n",
    "mlp_grid = GridSearchCV(estimator=MLPClassifier(random_state=4), param_grid=mlp_gs_params)\n",
    "mlp_grid.fit(standardised_x_train, y_train)\n",
    "print('GridSearchCV best score: %f' % mlp_grid.best_score_)\n",
    "print('GridSearchCV best estimator: %s' % mlp_grid.best_estimator_)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-04 12:39:12.686094\n",
      "OOB Accuracy Score: 0.933333\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        45\n",
      "   macro avg       0.92      0.93      0.92        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "GridSearchCV best score: 0.971429\n",
      "GridSearchCV best estimator: MLPClassifier(activation='logistic', alpha=3e-06, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=4, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "2018-10-04 12:42:57.030802\n"
     ]
    }
   ],
   "source": [
    "# OOB Multi-layer Perceptron max_iter=500\n",
    "print(datetime.datetime.now())\n",
    "mlp = MLPClassifier(max_iter=500, random_state=4)\n",
    "mlp.fit(standardised_x_train, y_train)\n",
    "mlp_pred = mlp.predict(standardised_x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, mlp_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, mlp_pred))\n",
    "\n",
    "# Multi-layer Perceptron with Grid Search\n",
    "mlp_gs_params = {'hidden_layer_sizes': [(100,), (100,100), (130,80,40)],\n",
    "                 'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                 'solver': ['lbfgs', 'sgd', 'adam'], \n",
    "                 'alpha': [0.000003, 0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003]}\n",
    "mlp_grid = GridSearchCV(estimator=MLPClassifier(max_iter=500, random_state=4), param_grid=mlp_gs_params)\n",
    "mlp_grid.fit(standardised_x_train, y_train)\n",
    "print('GridSearchCV best score: %f' % mlp_grid.best_score_)\n",
    "print('GridSearchCV best estimator: %s' % mlp_grid.best_estimator_)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.955556\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "GridSearchCV best score: 0.971429\n",
      "GridSearchCV best estimator: SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=4,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# OOB Support Vector Machine\n",
    "svm = SVC(random_state=4)\n",
    "svm.fit(standardised_x_train, y_train)\n",
    "svm_pred = svm.predict(standardised_x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, svm_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "# Support Vector Machine with Grid Search\n",
    "svm_gs_params = {'C': [0.03,0.1,0.3,1,3,10,30],\n",
    "                 'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "svm_grid = GridSearchCV(estimator=SVC(random_state=4), param_grid=svm_gs_params)\n",
    "svm_grid.fit(standardised_x_train, y_train)\n",
    "print('GridSearchCV best score: %f' % svm_grid.best_score_)\n",
    "print('GridSearchCV best estimator: %s' % svm_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.977778\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.93      1.00      0.97        14\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "GridSearchCV best score: 0.952381\n",
      "GridSearchCV best estimator: DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=4,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# OOB Decision Tree\n",
    "dtc = DecisionTreeClassifier(random_state=4)\n",
    "dtc.fit(x_train, y_train)\n",
    "dtc_pred = dtc.predict(x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, dtc_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, dtc_pred))\n",
    "\n",
    "# Decision Tree with Grid Search\n",
    "dtc_gs_params = {'criterion': ['gini', 'entropy']}\n",
    "dtc_grid = GridSearchCV(estimator=DecisionTreeClassifier(random_state=4), param_grid=dtc_gs_params)\n",
    "dtc_grid.fit(x_train, y_train)\n",
    "print('GridSearchCV best score: %f' % dtc_grid.best_score_)\n",
    "print('GridSearchCV best estimator: %s' % dtc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.977778\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.97      0.98      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OOB Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(standardised_x_train, y_train)\n",
    "gnb_pred = gnb.predict(standardised_x_test)\n",
    "print('OOB Accuracy Score: %f' % accuracy_score(y_test, gnb_pred))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, gnb_pred))\n",
    "\n",
    "# Naive Bayes with Grid Search\n",
    "# There were simple parameters to search through, so no grid search was performed for GaussianNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
